{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.optim import AdamW","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:07:40.966932Z","iopub.execute_input":"2025-06-11T08:07:40.967517Z","iopub.status.idle":"2025-06-11T08:07:40.971562Z","shell.execute_reply.started":"2025-06-11T08:07:40.967489Z","shell.execute_reply":"2025-06-11T08:07:40.970817Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\ndf = df[['text', 'airline_sentiment']]\ndf = df[df['airline_sentiment'].isin(['positive', 'neutral', 'negative'])]\n\n# Encode labels\nlabel_map = {'negative': 0, 'neutral': 1, 'positive': 2}\ndf['label'] = df['airline_sentiment'].map(label_map)\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:07:58.396428Z","iopub.execute_input":"2025-06-11T08:07:58.396716Z","iopub.status.idle":"2025-06-11T08:07:58.646845Z","shell.execute_reply.started":"2025-06-11T08:07:58.396694Z","shell.execute_reply":"2025-06-11T08:07:58.646243Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                text airline_sentiment  label\n0                @VirginAmerica What @dhepburn said.           neutral      1\n1  @VirginAmerica plus you've added commercials t...          positive      2\n2  @VirginAmerica I didn't today... Must mean I n...           neutral      1\n3  @VirginAmerica it's really aggressive to blast...          negative      0\n4  @VirginAmerica and it's a really big bad thing...          negative      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>airline_sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@VirginAmerica What @dhepburn said.</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@VirginAmerica plus you've added commercials t...</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@VirginAmerica it's really aggressive to blast...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@VirginAmerica and it's a really big bad thing...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:08:30.214480Z","iopub.execute_input":"2025-06-11T08:08:30.214760Z","iopub.status.idle":"2025-06-11T08:08:30.224976Z","shell.execute_reply.started":"2025-06-11T08:08:30.214737Z","shell.execute_reply":"2025-06-11T08:08:30.224177Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=128)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:08:41.759806Z","iopub.execute_input":"2025-06-11T08:08:41.760376Z","iopub.status.idle":"2025-06-11T08:08:48.629700Z","shell.execute_reply.started":"2025-06-11T08:08:41.760352Z","shell.execute_reply":"2025-06-11T08:08:48.629123Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a04477bc5b4f9d988fd2615e132501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d55b7520f79b43dfadfb011ae8916663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e46d0192972c49929750926a19986343"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a56293506b94f4086216a8328f26192"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()},torch.tensor(self.labels[idx])\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = SentimentDataset(train_encodings, train_labels)\nval_dataset = SentimentDataset(val_encodings, val_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:09:21.426088Z","iopub.execute_input":"2025-06-11T08:09:21.426694Z","iopub.status.idle":"2025-06-11T08:09:21.431382Z","shell.execute_reply.started":"2025-06-11T08:09:21.426669Z","shell.execute_reply":"2025-06-11T08:09:21.430760Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:09:29.843389Z","iopub.execute_input":"2025-06-11T08:09:29.843853Z","iopub.status.idle":"2025-06-11T08:09:32.683587Z","shell.execute_reply.started":"2025-06-11T08:09:29.843829Z","shell.execute_reply":"2025-06-11T08:09:32.682991Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a18ae71ddadc46d29783ecbf97525e89"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:09:47.755464Z","iopub.execute_input":"2025-06-11T08:09:47.755713Z","iopub.status.idle":"2025-06-11T08:09:47.759955Z","shell.execute_reply.started":"2025-06-11T08:09:47.755698Z","shell.execute_reply":"2025-06-11T08:09:47.759414Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:09:58.892826Z","iopub.execute_input":"2025-06-11T08:09:58.893093Z","iopub.status.idle":"2025-06-11T08:09:58.898068Z","shell.execute_reply.started":"2025-06-11T08:09:58.893075Z","shell.execute_reply":"2025-06-11T08:09:58.897256Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model.train()\nfor epoch in range(2):\n    total_loss = 0\n    for batch in train_loader:\n        inputs, labels = batch\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        labels = labels.to(device)\n\n        outputs = model(**inputs, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:10:09.457053Z","iopub.execute_input":"2025-06-11T08:10:09.457751Z","iopub.status.idle":"2025-06-11T08:13:07.510958Z","shell.execute_reply.started":"2025-06-11T08:10:09.457727Z","shell.execute_reply":"2025-06-11T08:13:07.510313Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 357.0910\nEpoch 2 Loss: 219.7593\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model.eval()\npredictions, true_labels = [], []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        inputs, labels = batch\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        labels = labels.to(device)\n\n        outputs = model(**inputs)\n        logits = outputs.logits\n        preds = torch.argmax(logits, dim=1)\n\n        predictions.extend(preds.cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\nprint(classification_report(true_labels, predictions, target_names=['Negative', 'Neutral', 'Positive']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:13:46.581142Z","iopub.execute_input":"2025-06-11T08:13:46.581538Z","iopub.status.idle":"2025-06-11T08:13:52.176188Z","shell.execute_reply.started":"2025-06-11T08:13:46.581511Z","shell.execute_reply":"2025-06-11T08:13:52.175525Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n    Negative       0.89      0.93      0.91      1889\n     Neutral       0.74      0.62      0.67       580\n    Positive       0.79      0.81      0.80       459\n\n    accuracy                           0.85      2928\n   macro avg       0.81      0.79      0.80      2928\nweighted avg       0.85      0.85      0.85      2928\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def predict_sentiment(text):\n    model.eval()\n    tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n    tokens = {k: v.to(device) for k, v in tokens.items()}\n    with torch.no_grad():\n        output = model(**tokens)\n        pred = torch.argmax(output.logits, dim=1).item()\n    return {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}[pred]\n\nprint(predict_sentiment(\"I love or don't like this airline!\"))\nprint(predict_sentiment(\"This flight was okay.\"))\nprint(predict_sentiment(\"Terrible service.\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:16:59.832755Z","iopub.execute_input":"2025-06-11T08:16:59.833297Z","iopub.status.idle":"2025-06-11T08:16:59.867244Z","shell.execute_reply.started":"2025-06-11T08:16:59.833251Z","shell.execute_reply":"2025-06-11T08:16:59.866526Z"}},"outputs":[{"name":"stdout","text":"Negative\nPositive\nNegative\n","output_type":"stream"}],"execution_count":18}]}